{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, cast, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ..transforms._presets import ImageClassification\n",
    "from ..utils import _log_api_usage_once\n",
    "from ._api import register_model, Weights, WeightsEnum\n",
    "from ._meta import _IMAGENET_CATEGORIES\n",
    "from ._utils import _ovewrite_named_param, handle_legacy_interface\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"VGG\",\n",
    "    \"VGG11_Weights\",\n",
    "    \"VGG11_BN_Weights\",\n",
    "    \"VGG13_Weights\",\n",
    "    \"VGG13_BN_Weights\",\n",
    "    \"VGG16_Weights\",\n",
    "    \"VGG16_BN_Weights\",\n",
    "    \"VGG19_Weights\",\n",
    "    \"VGG19_BN_Weights\",\n",
    "    \"vgg11\",\n",
    "    \"vgg11_bn\",\n",
    "    \"vgg13\",\n",
    "    \"vgg13_bn\",\n",
    "    \"vgg16\",\n",
    "    \"vgg16_bn\",\n",
    "    \"vgg19\",\n",
    "    \"vgg19_bn\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG网络的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # 用于检测并记录API的调用\n",
    "        _log_api_usage_once(self)\n",
    "        # 网络的卷积层\n",
    "        self.features = features\n",
    "        # 平均池化\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        # 在卷积层之后的3个全连接层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        # 初始化不同网络层的权重\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        # 将卷积层的输出展开为一维向量\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成卷积层的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\n",
    "    layers: List[nn.Module] = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            # v为\"M\"，代表卷积块之间的池化层\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            v = cast(int, v)\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置不同类型网络的参数信息，A是VGG11，B是VGG13，D是VGG16，E是VGG19，M表示不同卷积块之间的分隔，数字表示卷积层的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs: Dict[str, List[Union[str, int]]] = {\n",
    "    \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有网络都是通过该函数生成的，第一个参数cfg对应着不同的网络，该参数根据cfgs中给定的配置来得到相应网络的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vgg(cfg: str, batch_norm: bool, weights: Optional[WeightsEnum], progress: bool, **kwargs: Any) -> VGG:\n",
    "    if weights is not None:\n",
    "        kwargs[\"init_weights\"] = False\n",
    "        if weights.meta[\"categories\"] is not None:\n",
    "            _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_COMMON_META = {\n",
    "    \"min_size\": (32, 32),\n",
    "    \"categories\": _IMAGENET_CATEGORIES,\n",
    "    \"recipe\": \"https://github.com/pytorch/vision/tree/main/references/classification#alexnet-and-vgg\",\n",
    "    \"_docs\": \"\"\"These weights were trained from scratch by using a simplified training recipe.\"\"\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下的类会得到相应网络已经训练好的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg11-8a719046.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 132863336,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 69.020,\n",
    "                    \"acc@5\": 88.628,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.609,\n",
    "            \"_file_size\": 506.84,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG11_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 132868840,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 70.370,\n",
    "                    \"acc@5\": 89.810,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.609,\n",
    "            \"_file_size\": 506.881,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG13_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg13-19584684.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 133047848,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 69.928,\n",
    "                    \"acc@5\": 89.246,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 11.308,\n",
    "            \"_file_size\": 507.545,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG13_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 133053736,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 71.586,\n",
    "                    \"acc@5\": 90.374,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 11.308,\n",
    "            \"_file_size\": 507.59,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG16_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg16-397923af.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138357544,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 71.592,\n",
    "                    \"acc@5\": 90.382,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.796,\n",
    "        },\n",
    "    )\n",
    "    IMAGENET1K_FEATURES = Weights(\n",
    "        # Weights ported from https://github.com/amdegroot/ssd.pytorch/\n",
    "        url=\"https://download.pytorch.org/models/vgg16_features-amdegroot-88682ab5.pth\",\n",
    "        transforms=partial(\n",
    "            ImageClassification,\n",
    "            crop_size=224,\n",
    "            mean=(0.48235, 0.45882, 0.40784),\n",
    "            std=(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0),\n",
    "        ),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138357544,\n",
    "            \"categories\": None,\n",
    "            \"recipe\": \"https://github.com/amdegroot/ssd.pytorch#training-ssd\",\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": float(\"nan\"),\n",
    "                    \"acc@5\": float(\"nan\"),\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.802,\n",
    "            \"_docs\": \"\"\"\n",
    "                These weights can't be used for classification because they are missing values in the `classifier`\n",
    "                module. Only the `features` module has valid values and can be used for feature extraction. The weights\n",
    "                were trained using the original input standardization method as described in the paper.\n",
    "            \"\"\",\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG16_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 138365992,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 73.360,\n",
    "                    \"acc@5\": 91.516,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 15.47,\n",
    "            \"_file_size\": 527.866,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG19_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 143667240,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 72.376,\n",
    "                    \"acc@5\": 90.876,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 19.632,\n",
    "            \"_file_size\": 548.051,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class VGG19_BN_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 143678248,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 74.218,\n",
    "                    \"acc@5\": 91.842,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 19.632,\n",
    "            \"_file_size\": 548.143,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下函数是不同层数的VGG网络，带有后缀_bn的函数代表网络加了BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG11_Weights.IMAGENET1K_V1))\n",
    "def vgg11(*, weights: Optional[VGG11_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-11 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG11_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG11_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG11_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG11_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"A\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG11_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg11_bn(*, weights: Optional[VGG11_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-11-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG11_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG11_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG11_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG11_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"A\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG13_Weights.IMAGENET1K_V1))\n",
    "def vgg13(*, weights: Optional[VGG13_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-13 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG13_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG13_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG13_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG13_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"B\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG13_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg13_bn(*, weights: Optional[VGG13_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-13-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG13_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG13_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG13_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG13_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"B\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG16_Weights.IMAGENET1K_V1))\n",
    "def vgg16(*, weights: Optional[VGG16_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-16 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG16_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG16_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG16_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG16_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"D\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG16_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg16_bn(*, weights: Optional[VGG16_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-16-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG16_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG16_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG16_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG16_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"D\", True, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG19_Weights.IMAGENET1K_V1))\n",
    "def vgg19(*, weights: Optional[VGG19_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-19 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG19_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG19_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG19_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG19_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"E\", False, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", VGG19_BN_Weights.IMAGENET1K_V1))\n",
    "def vgg19_bn(*, weights: Optional[VGG19_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\n",
    "    \"\"\"VGG-19_BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.VGG19_BN_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.VGG19_BN_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n",
    "            for more details about this class.\n",
    "    .. autoclass:: torchvision.models.VGG19_BN_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = VGG19_BN_Weights.verify(weights)\n",
    "\n",
    "    return _vgg(\"E\", True, weights, progress, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
